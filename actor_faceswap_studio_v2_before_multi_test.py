#!/usr/bin/env python3
"""
üé¨ Actor Face Swap Studio V2
Application personnalis√©e pour le face swapping d'acteurs sur des vid√©os
Utilise FaceFusion en ligne de commande (headless mode)
"""

import os
import subprocess
from pathlib import Path
from typing import Optional, Tuple
import gradio as gr
import shutil

# Configuration des chemins
BASE_DIR = Path(__file__).parent
FACEFUSION_DIR = BASE_DIR / 'facefusion'
UPLOADS_DIR = BASE_DIR / 'uploads'
OUTPUTS_DIR = BASE_DIR / 'outputs'
TEMP_DIR = BASE_DIR / 'temp'

# Cr√©er les dossiers n√©cessaires
for directory in [UPLOADS_DIR, OUTPUTS_DIR, TEMP_DIR]:
    directory.mkdir(exist_ok=True)


class FaceSwapConfig:
    """Configuration des presets de qualit√©"""

    PRESETS = {
        'rapide': {
            'name': '‚ö° Rapide',
            'description': 'Tests rapides - qualit√© standard',
            'face_swapper_model': 'inswapper_128',
            'face_swapper_pixel_boost': '256x256',
            'face_enhancer_model': 'gfpgan_1.4',
            'face_enhancer_blend': '60',
            'face_detector_size': '640x640',
            'reference_face_distance': '0.6',
            'output_video_quality': 80,
            'face_enhancer': True,
            'lip_sync': True
        },
        'equilibre': {
            'name': '‚öñÔ∏è Optimal',
            'description': 'RESSEMBLANCE MAXIMALE - Configuration optimale',
            'face_swapper_model': 'inswapper_128_fp16',
            'face_swapper_pixel_boost': '512x512',
            'face_enhancer_model': 'codeformer',
            'face_enhancer_blend': '80',
            'face_detector_size': '640x640',
            'reference_face_distance': '0.6',
            'output_video_quality': 90,
            'face_enhancer': True,
            'lip_sync': True
        },
        'haute_qualite': {
            'name': 'üíé Haute Qualit√©',
            'description': 'Qualit√© maximale - YouTube/Production',
            'face_swapper_model': 'inswapper_128_fp16',
            'face_swapper_pixel_boost': '1024x1024',
            'face_enhancer_model': 'codeformer',
            'face_enhancer_blend': '85',
            'face_detector_size': '640x640',
            'reference_face_distance': '0.6',
            'output_video_quality': 95,
            'face_enhancer': True,
            'lip_sync': True
        }
    }

    FACE_SWAPPER_MODELS = [
        'inswapper_128',
        'inswapper_128_fp16',
        'hyperswap_1a_256',
        'hyperswap_1b_256',
        'simswap_256',
        'ghost_2_256',
        'blendswap_256'
    ]

    LIP_SYNC_MODELS = [
        'wav2lip_gan_96',
        'wav2lip_96',
        'edtalk_256'
    ]

    FACE_ENHANCER_MODELS = [
        'codeformer',
        'gfpgan_1.4',
        'gfpgan_1.3',
        'gfpgan_1.2'
    ]

    FACE_DETECTOR_SIZES = [
        '640x640'  # Seule valeur accept√©e par FaceFusion
    ]


class FaceSwapProcessor:
    """Gestionnaire du traitement de face swap via CLI"""

    def __init__(self):
        self.facefusion_script = FACEFUSION_DIR / 'facefusion.py'

    def validate_inputs(self, source_path: str, target_path: str) -> Tuple[bool, str]:
        """Valide les fichiers d'entr√©e"""
        if not source_path or not os.path.exists(source_path):
            return False, "‚ùå Veuillez charger une photo source (portrait de l'acteur)"

        if not target_path or not os.path.exists(target_path):
            return False, "‚ùå Veuillez charger une vid√©o cible"

        if not self.facefusion_script.exists():
            return False, f"‚ùå FaceFusion non trouv√© √† {self.facefusion_script}"

        return True, "‚úÖ Fichiers valid√©s"

    def build_command(
        self,
        source_path: str,
        target_path: str,
        output_path: str,
        audio_path: Optional[str],
        face_swapper_model: str,
        pixel_boost: str,
        face_enhancer: bool,
        face_enhancer_model: str,
        face_enhancer_blend: str,
        face_detector_size: str,
        reference_face_distance: str,
        lip_sync_enabled: bool,
        lip_sync_model: str,
        execution_provider: str,
        output_video_quality: int
    ) -> list:
        """Construit la commande FaceFusion avec param√®tres optimaux"""

        cmd = [
            'python3',
            str(self.facefusion_script),
            'headless-run',  # Mode headless pour automatisation
        ]

        # Source paths: image + audio (si lip sync activ√©)
        if audio_path:
            # Audio + Image dans --source-paths (ordre important)
            cmd.extend(['--source-paths', audio_path, source_path])
        else:
            # Juste l'image
            cmd.extend(['--source-paths', source_path])

        # Target et output
        cmd.extend([
            '--target-path', target_path,
            '--output-path', output_path,
        ])

        # Processeurs (l'ordre est important)
        processors = ['face_swapper']
        if face_enhancer:
            processors.append('face_enhancer')
        if lip_sync_enabled:
            processors.append('lip_syncer')

        cmd.append('--processors')
        cmd.extend(processors)

        # Face swapper options
        cmd.extend([
            '--face-swapper-model', face_swapper_model,
            '--face-swapper-pixel-boost', pixel_boost
        ])

        # Face detector options (CRITIQUE pour ressemblance)
        cmd.extend([
            '--face-detector-size', face_detector_size,
            '--face-detector-score', '0.5'
        ])

        # Reference face distance (PARAM√àTRE CL√â pour ressemblance)
        cmd.extend([
            '--reference-face-distance', str(reference_face_distance),
            '--face-selector-mode', 'reference',
            '--face-selector-order', 'large-small'
        ])

        # Face enhancer options (avec mod√®le configurable)
        if face_enhancer:
            cmd.extend([
                '--face-enhancer-model', face_enhancer_model,
                '--face-enhancer-blend', str(face_enhancer_blend)
            ])

        # Lip sync options
        if lip_sync_enabled:
            cmd.extend([
                '--lip-syncer-model', lip_sync_model,
                '--lip-syncer-weight', '1.0'
            ])

        # Execution
        cmd.extend([
            '--execution-providers', execution_provider,
            '--execution-thread-count', '16'
        ])

        # Output
        cmd.extend([
            '--output-video-encoder', 'libx264',
            '--output-video-quality', str(output_video_quality)
        ])

        return cmd

    def extract_audio(self, target_video_path: str) -> Tuple[bool, Optional[str]]:
        """Extrait la piste audio en WAV pour le lip syncer"""

        audio_output = TEMP_DIR / f"{Path(target_video_path).stem}_audio.wav"

        cmd = [
            'ffmpeg', '-y',
            '-i', target_video_path,
            '-vn',
            '-ac', '1',
            '-ar', '44100',
            str(audio_output)
        ]

        try:
            subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
        except subprocess.CalledProcessError as exc:
            print(f"‚ùå Extraction audio √©chou√©e: {exc.stderr}")
            return False, None

        if not audio_output.exists() or audio_output.stat().st_size == 0:
            print("‚ùå Extraction audio √©chou√©e: fichier vide")
            return False, None

        return True, str(audio_output)

    def merge_audio_into_video(self, video_path: str, audio_path: str) -> Tuple[bool, str]:
        """Relie l'audio trait√© √† la vid√©o finale pour le t√©l√©chargement"""

        merged_path = TEMP_DIR / f"{Path(video_path).stem}_with_audio.mp4"

        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-shortest',
            str(merged_path)
        ]

        try:
            subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
        except subprocess.CalledProcessError as exc:
            print(f"‚ùå Fusion audio/vid√©o √©chou√©e: {exc.stderr}")
            return False, video_path

        # Remplacer le fichier original par la version avec audio
        shutil.move(str(merged_path), video_path)
        return True, video_path

    def process_video(
        self,
        source_image_path: str,
        target_video_path: str,
        preset: str,
        face_swapper_model: str,
        pixel_boost: str,
        face_enhancer: bool,
        face_enhancer_model: str,
        face_enhancer_blend: str,
        face_detector_size: str,
        reference_face_distance: str,
        lip_sync_enabled: bool,
        lip_sync_model: str,
        execution_provider: str,
        output_video_quality: int,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], str]:
        """
        Traite la vid√©o avec face swap et param√®tres optimaux

        Returns:
            Tuple[output_path, message]
        """
        try:
            # Validation
            valid, message = self.validate_inputs(source_image_path, target_video_path)
            if not valid:
                return None, message

            progress(0.1, desc="üîç Validation des fichiers...")

            # Pr√©paration de la sortie
            output_filename = f"faceswap_{Path(target_video_path).stem}_{preset}.mp4"
            output_path = str(OUTPUTS_DIR / output_filename)

            # Extraction audio si lip sync activ√©
            audio_path: Optional[str] = None
            if lip_sync_enabled:
                progress(0.25, desc="üéµ Extraction de l'audio pour le lip sync...")
                ok, extracted_audio = self.extract_audio(target_video_path)
                if not ok or not extracted_audio:
                    return None, "‚ùå √âchec de l'extraction audio pour le lip sync. V√©rifiez que la vid√©o contient une piste audio."
                audio_path = extracted_audio

            progress(0.35, desc="‚öôÔ∏è Construction de la commande...")

            # Construire la commande
            cmd = self.build_command(
                source_image_path,
                target_video_path,
                output_path,
                audio_path,
                face_swapper_model,
                pixel_boost,
                face_enhancer,
                face_enhancer_model,
                face_enhancer_blend,
                face_detector_size,
                reference_face_distance,
                lip_sync_enabled,
                lip_sync_model,
                execution_provider,
                output_video_quality
            )

            print(f"\nüöÄ Commande FaceFusion:")
            print(f"   {' '.join(cmd)}\n")

            progress(0.45, desc="üé¨ Lancement du traitement FaceFusion...")

            # Lancer la commande
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                cwd=str(FACEFUSION_DIR)
            )

            # Lire la sortie en temps r√©el
            progress(0.55, desc="üé≠ Traitement en cours...")
            for line in process.stdout:
                print(line.rstrip())
                # Mise √† jour de la progression bas√©e sur les logs
                if 'Processing' in line or 'Extracting' in line:
                    progress(0.65, desc="üé¨ Traitement des frames...")
                elif 'Merging' in line or 'Encoding' in line:
                    progress(0.8, desc="üé• Encodage de la vid√©o...")

            # Attendre la fin
            return_code = process.wait()

            if return_code != 0:
                return None, f"‚ùå Erreur lors du traitement (code: {return_code})\n\nVoir les logs dans le terminal."

            progress(0.9, desc="üéâ Finalisation...")

            # V√©rifier que le fichier de sortie existe
            if not os.path.exists(output_path):
                return None, "‚ùå Le fichier de sortie n'a pas √©t√© cr√©√©"

            # Fusion audio si lip sync √©tait activ√©
            if lip_sync_enabled and audio_path:
                progress(0.92, desc="üîä Fusion de l'audio final...")
                merged, output_path = self.merge_audio_into_video(output_path, audio_path)
                if not merged:
                    return None, "‚ùå Fusion audio/vid√©o √©chou√©e. Consultez les logs."

            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB

            progress(1.0, desc="‚úÖ Termin√© !")

            success_msg = f"""‚úÖ Face swap termin√© avec succ√®s !

üìÅ Fichier: {output_filename}
üíæ Taille: {file_size:.2f} MB
üìÇ Dossier: {OUTPUTS_DIR}

{'üé§ Lip sync activ√©' if lip_sync_enabled else ''}
{'‚ú® Face enhancer activ√©' if face_enhancer else ''}
"""
            return output_path, success_msg

        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            print(f"\n‚ùå ERREUR:\n{error_trace}\n")
            return None, f"‚ùå Erreur: {str(e)}\n\n‚ö†Ô∏è Voir les logs dans le terminal."


# Instance globale du processeur
processor = FaceSwapProcessor()


def create_gradio_interface():
    """Cr√©e l'interface Gradio personnalis√©e"""

    # D√©tection des providers disponibles
    # Par d√©faut on propose cpu et cuda
    available_providers = ['cpu', 'cuda', 'coreml']
    default_provider = 'cuda'

    # Th√®me personnalis√©
    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="indigo",
        neutral_hue="slate",
        font=gr.themes.GoogleFont("Inter")
    )

    with gr.Blocks(
        title="üé¨ Actor Face Swap Studio",
        theme=theme,
        css="""
        .main-header {
            text-align: center;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 10px;
            color: white;
            margin-bottom: 20px;
        }
        .info-box {
            background-color: #f0f9ff;
            border-left: 4px solid #3b82f6;
            padding: 12px;
            margin: 10px 0;
            border-radius: 4px;
        }
        """
    ) as app:

        # Header
        gr.HTML("""
        <div class="main-header">
            <h1>üé¨ Actor Face Swap Studio</h1>
            <p>Remplacez le visage d'un acteur dans vos vid√©os avec intelligence artificielle</p>
            <p style="font-size: 0.9em; opacity: 0.9;">Propuls√© par FaceFusion CLI</p>
        </div>
        """)

        gr.Markdown("""
        ### üìã Mode d'emploi :
        1. Chargez le portrait de votre acteur
        2. Chargez la vid√©o
        3. Choisissez un preset ou ajustez les param√®tres
        4. Cliquez sur "Lancer le Face Swap"
        """)

        with gr.Row():
            # Colonne gauche: Fichiers
            with gr.Column(scale=1):
                gr.Markdown("### üìÅ Fichiers d'entr√©e")

                source_image = gr.Image(
                    label="üé≠ Portrait de l'acteur",
                    type="filepath",
                    sources=["upload"],
                    height=250
                )

                target_video = gr.Video(
                    label="üé• Vid√©o cible",
                    sources=["upload"],
                    height=250
                )

            # Colonne centrale: Param√®tres
            with gr.Column(scale=1):
                gr.Markdown("### ‚öôÔ∏è Configuration")

                preset_radio = gr.Radio(
                    choices=[
                        ('‚ö° Rapide - Tests', 'rapide'),
                        ('‚öñÔ∏è √âquilibr√© - Recommand√©', 'equilibre'),
                        ('üíé Haute Qualit√© - Production', 'haute_qualite')
                    ],
                    value='equilibre',
                    label="Preset de qualit√©"
                )

                preset_info = gr.Markdown(FaceSwapConfig.PRESETS['equilibre']['description'])

                with gr.Accordion("üîß Param√®tres avanc√©s", open=False):
                    gr.Markdown("#### üé≠ Face Swapper")

                    face_swapper_model = gr.Dropdown(
                        choices=FaceSwapConfig.FACE_SWAPPER_MODELS,
                        value='inswapper_128_fp16',
                        label="Mod√®le de face swap",
                        info="inswapper_128_fp16 = meilleure ressemblance"
                    )

                    pixel_boost = gr.Radio(
                        choices=['256x256', '512x512', '1024x1024'],
                        value='512x512',
                        label="R√©solution (Pixel Boost)"
                    )

                    gr.Markdown("#### ‚ú® Face Enhancer")

                    face_enhancer = gr.Checkbox(
                        label="‚ú® Activer l'am√©lioration du visage",
                        value=True,
                        info="OBLIGATOIRE pour ressemblance optimale"
                    )

                    face_enhancer_model = gr.Dropdown(
                        choices=FaceSwapConfig.FACE_ENHANCER_MODELS,
                        value='codeformer',
                        label="Mod√®le d'am√©lioration",
                        info="CodeFormer pr√©serve mieux l'identit√©"
                    )

                    face_enhancer_blend = gr.Slider(
                        minimum=50,
                        maximum=100,
                        value=80,
                        step=5,
                        label="Intensit√© de l'am√©lioration (%)"
                    )

                    gr.Markdown("#### üéØ D√©tection et Ressemblance (CRITIQUE)")

                    face_detector_size = gr.Radio(
                        choices=FaceSwapConfig.FACE_DETECTOR_SIZES,
                        value='640x640',
                        label="Taille du d√©tecteur",
                        info="640x640 (seule valeur disponible dans FaceFusion)"
                    )

                    reference_face_distance = gr.Slider(
                        minimum=0.3,
                        maximum=1.5,
                        value=0.6,
                        step=0.1,
                        label="Distance de r√©f√©rence",
                        info="0.6 = optimal | < 0.6 = strict | > 0.6 = permissif"
                    )

                    gr.Markdown("#### üé§ Lip Sync")

                    lip_sync_enabled = gr.Checkbox(
                        label="üé§ Activer la synchronisation labiale",
                        value=True,
                        info="RECOMMAND√â si l'acteur parle"
                    )

                    lip_sync_model = gr.Dropdown(
                        choices=FaceSwapConfig.LIP_SYNC_MODELS,
                        value='wav2lip_gan_96',
                        label="Mod√®le de Lip Sync"
                    )

                    gr.Markdown("#### ‚öôÔ∏è Ex√©cution")

                    execution_provider = gr.Dropdown(
                        choices=available_providers,
                        value=default_provider,
                        label="Provider d'ex√©cution",
                        info="cuda pour GPU, cpu sinon"
                    )

                    output_video_quality = gr.Slider(
                        minimum=70,
                        maximum=100,
                        value=90,
                        step=5,
                        label="Qualit√© vid√©o de sortie (%)"
                    )

                gr.Markdown("---")
                process_btn = gr.Button(
                    "üöÄ Lancer le Face Swap",
                    variant="primary",
                    size="lg"
                )

                status_text = gr.Textbox(
                    label="üìä Statut",
                    value="En attente...",
                    interactive=False,
                    lines=6
                )

            # Colonne droite: R√©sultat
            with gr.Column(scale=1):
                gr.Markdown("### üéâ R√©sultat")

                output_video = gr.Video(
                    label="‚ú® Vid√©o avec face swap",
                    height=500
                )

                gr.Markdown("""
                <div class="info-box">
                üí° <b>Astuce:</b> Les vid√©os sont sauvegard√©es dans <code>outputs/</code>
                </div>
                """)

        # Footer
        gr.Markdown("""
        ---
        ### üí° Conseils pour RESSEMBLANCE MAXIMALE:
        - **Mod√®le**: `inswapper_128_fp16` (meilleure fid√©lit√© d'identit√©)
        - **Face Enhancer**: `codeformer` √† 80% (pr√©serve les traits uniques)
        - **Distance**: 0.6 optimal | 0.3-0.5 pour strict | 0.8-1.2 pour angles difficiles
        - **D√©tecteur**: 1024x1024 pour vid√©os HD (capture micro-expressions)
        - **Lip Sync**: Am√©liore le r√©sultat de 60-80% pour dialogues
        - **Photo source**: Bien √©clair√©e, expression neutre, haute r√©solution
        - Les logs d√©taill√©s s'affichent dans le terminal
        """)

        # Logique de mise √† jour du preset
        def update_preset(preset_name):
            preset = FaceSwapConfig.PRESETS[preset_name]
            return [
                preset['description'],
                preset['face_swapper_model'],
                preset['face_swapper_pixel_boost'],
                preset['face_enhancer'],
                preset['face_enhancer_model'],
                preset['face_enhancer_blend'],
                preset['face_detector_size'],
                preset['reference_face_distance'],
                preset['lip_sync'],
                preset['output_video_quality']
            ]

        preset_radio.change(
            fn=update_preset,
            inputs=[preset_radio],
            outputs=[
                preset_info,
                face_swapper_model,
                pixel_boost,
                face_enhancer,
                face_enhancer_model,
                face_enhancer_blend,
                face_detector_size,
                reference_face_distance,
                lip_sync_enabled,
                output_video_quality
            ]
        )

        # √âv√©nement de traitement
        process_btn.click(
            fn=processor.process_video,
            inputs=[
                source_image,
                target_video,
                preset_radio,
                face_swapper_model,
                pixel_boost,
                face_enhancer,
                face_enhancer_model,
                face_enhancer_blend,
                face_detector_size,
                reference_face_distance,
                lip_sync_enabled,
                lip_sync_model,
                execution_provider,
                output_video_quality
            ],
            outputs=[output_video, status_text]
        )

    return app


def main():
    """Point d'entr√©e principal"""

    print("üé¨ Actor Face Swap Studio V2 - D√©marrage...")
    print(f"üìÅ FaceFusion: {FACEFUSION_DIR}")
    print(f"üìÅ Outputs: {OUTPUTS_DIR}")

    if not FACEFUSION_DIR.exists():
        print(f"‚ùå ERREUR: FaceFusion non trouv√© √† {FACEFUSION_DIR}")
        print("   Assurez-vous d'avoir install√© FaceFusion dans le dossier 'facefusion'")
        return

    app = create_gradio_interface()

    print("\n" + "="*60)
    print("‚úÖ Interface pr√™te !")
    print("="*60 + "\n")

    # Try to use the GRADIO_SERVER_PORT environment variable, otherwise default to 7861
    import os
    port = int(os.environ.get('GRADIO_SERVER_PORT', 7861))

    app.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        inbrowser=True,
        show_error=True
    )


if __name__ == "__main__":
    main()
